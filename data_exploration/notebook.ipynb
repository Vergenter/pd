{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KYEWORD EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/jvm/java-11-openjdk-amd64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/21 19:21:17 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.178 instead (on interface enp4s0)\n",
      "22/06/21 19:21:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/vergenter/Venvs/sparkNLPVenv/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/vergenter/Venvs/sparkNLPVenv/lib/python3.10/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/vergenter/.ivy2/cache\n",
      "The jars for the packages stored in: /home/vergenter/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      "org.neo4j#neo4j-connector-apache-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-00d68bf0-7081-454a-a5aa-e6d7455d4776;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.0.0 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.2 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12;4.1.2_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12_common;4.1.2 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver;4.4.5 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound org.apache.xbean#xbean-asm6-shaded;4.10 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2020.1.4 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.0 in central\n",
      ":: resolution report :: resolve 513ms :: artifacts dl 13ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.0.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.2 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.apache.xbean#xbean-asm6-shaded;4.10 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12;4.1.2_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12_common;4.1.2 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2020.1.4 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver;4.4.5 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   0   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-00d68bf0-7081-454a-a5aa-e6d7455d4776\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/13ms)\n",
      "22/06/21 19:21:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "print(os.getenv(\"JAVA_HOME\"))\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "    .config(\"spark.driver.memory\", \"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.0.0,org.neo4j:neo4j-connector-apache-spark_2.12:4.1.2_for_spark_3\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, text: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "articles_abstracts = spark.read.format(\"org.neo4j.spark.DataSource\")\\\n",
    "  .option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    "  .option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    "  .option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"]).option(\"query\", \"MATCH (n:Article) where n.language =\\\"en\\\" WITH n RETURN n.id as id,n.title +'. '+ n.abstract as text\")\\\n",
    "  .option(\"partitions\", \"4\")\\\n",
    "  .load()\n",
    "articles_abstracts.persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import DocumentAssembler,Pipeline,LightPipeline\n",
    "from sparknlp.annotator import StopWordsCleaner,SentenceDetector,Tokenizer,YakeKeywordExtraction,BertForTokenClassification,NerConverter,LemmatizerModel,Normalizer,Word2VecModel\n",
    "# Transforms the raw text into a document readable by the later stages of the\n",
    "# pipeline\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "# Separates the document into sentences\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('sentences')# \\\n",
    "    #.setDetectLists(True)\n",
    "\n",
    "# Separates sentences into individial tokens (words)\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['sentences']) \\\n",
    "    .setOutputCol('tokens') \\\n",
    "    .setContextChars(['(', ')', '?', '!', '.', ','])\n",
    "\n",
    "# The keyphrase extraction model. Change MinNGrams and MaxNGrams to set the\n",
    "# minimum and maximum length of possible keyphrases, and change NKeywords to\n",
    "# set the amount of potential keyphrases identified per document.\n",
    "keywords = YakeKeywordExtraction() \\\n",
    "    .setInputCols('tokens') \\\n",
    "    .setOutputCol('keywords') \\\n",
    "    .setMinNGrams(2) \\\n",
    "    .setMaxNGrams(5) \\\n",
    "    .setNKeywords(10) \\\n",
    "    .setStopWords(StopWordsCleaner().getStopWords())\n",
    "\n",
    "\n",
    "# Assemble all of these stages into a pipeline, then fit the pipeline on an\n",
    "# empty data frame so it can be used to transform new inputs.\n",
    "pipeline_keywords = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    keywords\n",
    "])\n",
    "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
    "keywords_model = pipeline_keywords.fit(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, keywords: array<struct<0:string,1:string>>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_keywords = keywords_model.transform(articles_abstracts).select(F.col(\"id\"),F.arrays_zip(F.expr(\"transform(keywords.metadata,i -> i['score'])\"),F.col(\"keywords.result\")).alias(\"keywords\"))\n",
    "with_keywords.cache()\n",
    "# 15m 10.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/21 12:27:27 ERROR Neo4jDataWriter: Cannot commit the transaction because the following exception\n",
      "org.neo4j.driver.exceptions.TransientException: ForsetiClient[transactionId=280, clientId=4] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=283, clientId=5]} on NODE_RELATIONSHIP_GROUP_DELETE(606840), because holders of that lock are waiting for ForsetiClient[transactionId=280, clientId=4].\n",
      " Wait list:ExclusiveLock[\n",
      "Client[283] waits for [ForsetiClient[transactionId=280, clientId=4]]]\n",
      "\tat org.neo4j.driver.internal.util.Futures.blockingGet(Futures.java:144)\n",
      "\tat org.neo4j.driver.internal.InternalTransaction.run(InternalTransaction.java:60)\n",
      "\tat org.neo4j.driver.internal.AbstractQueryRunner.run(AbstractQueryRunner.java:37)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:64)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.write(BaseDataWriter.scala:45)\n",
      "\tat org.neo4j.spark.writer.Neo4jDataWriter.write(Neo4jDataWriter.scala:9)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:416)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tSuppressed: org.neo4j.driver.internal.util.ErrorUtil$InternalExceptionCause\n",
      "\t\tat org.neo4j.driver.internal.util.ErrorUtil.newNeo4jError(ErrorUtil.java:103)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageDispatcher.handleFailureMessage(InboundMessageDispatcher.java:122)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.unpackFailureMessage(CommonMessageReader.java:83)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.read(CommonMessageReader.java:59)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:83)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:35)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.MessageDecoder.channelRead(MessageDecoder.java:47)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t\t... 1 more\n",
      "22/06/21 12:27:27 ERROR Utils: Aborting task\n",
      "org.neo4j.driver.exceptions.TransientException: ForsetiClient[transactionId=280, clientId=4] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=283, clientId=5]} on NODE_RELATIONSHIP_GROUP_DELETE(606840), because holders of that lock are waiting for ForsetiClient[transactionId=280, clientId=4].\n",
      " Wait list:ExclusiveLock[\n",
      "Client[283] waits for [ForsetiClient[transactionId=280, clientId=4]]]\n",
      "\tat org.neo4j.driver.internal.util.Futures.blockingGet(Futures.java:144)\n",
      "\tat org.neo4j.driver.internal.InternalTransaction.run(InternalTransaction.java:60)\n",
      "\tat org.neo4j.driver.internal.AbstractQueryRunner.run(AbstractQueryRunner.java:37)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:64)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.write(BaseDataWriter.scala:45)\n",
      "\tat org.neo4j.spark.writer.Neo4jDataWriter.write(Neo4jDataWriter.scala:9)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:416)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tSuppressed: org.neo4j.driver.internal.util.ErrorUtil$InternalExceptionCause\n",
      "\t\tat org.neo4j.driver.internal.util.ErrorUtil.newNeo4jError(ErrorUtil.java:103)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageDispatcher.handleFailureMessage(InboundMessageDispatcher.java:122)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.unpackFailureMessage(CommonMessageReader.java:83)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.read(CommonMessageReader.java:59)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:83)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:35)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.MessageDecoder.channelRead(MessageDecoder.java:47)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t\t... 1 more\n",
      "22/06/21 12:27:27 ERROR DataWritingSparkTask: Aborting commit for partition 3 (task 4, attempt 0, stage 1.0)\n",
      "22/06/21 12:27:27 ERROR DataWritingSparkTask: Aborted commit for partition 3 (task 4, attempt 0, stage 1.0)\n",
      "22/06/21 12:27:27 ERROR Executor: Exception in task 3.0 in stage 1.0 (TID 4)\n",
      "org.neo4j.driver.exceptions.TransientException: ForsetiClient[transactionId=280, clientId=4] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=283, clientId=5]} on NODE_RELATIONSHIP_GROUP_DELETE(606840), because holders of that lock are waiting for ForsetiClient[transactionId=280, clientId=4].\n",
      " Wait list:ExclusiveLock[\n",
      "Client[283] waits for [ForsetiClient[transactionId=280, clientId=4]]]\n",
      "\tat org.neo4j.driver.internal.util.Futures.blockingGet(Futures.java:144)\n",
      "\tat org.neo4j.driver.internal.InternalTransaction.run(InternalTransaction.java:60)\n",
      "\tat org.neo4j.driver.internal.AbstractQueryRunner.run(AbstractQueryRunner.java:37)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:64)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.write(BaseDataWriter.scala:45)\n",
      "\tat org.neo4j.spark.writer.Neo4jDataWriter.write(Neo4jDataWriter.scala:9)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:416)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tSuppressed: org.neo4j.driver.internal.util.ErrorUtil$InternalExceptionCause\n",
      "\t\tat org.neo4j.driver.internal.util.ErrorUtil.newNeo4jError(ErrorUtil.java:103)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageDispatcher.handleFailureMessage(InboundMessageDispatcher.java:122)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.unpackFailureMessage(CommonMessageReader.java:83)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.read(CommonMessageReader.java:59)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:83)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:35)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.MessageDecoder.channelRead(MessageDecoder.java:47)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t\t... 1 more\n",
      "22/06/21 12:27:27 WARN TaskSetManager: Lost task 3.0 in stage 1.0 (TID 4) (192.168.0.178 executor driver): org.neo4j.driver.exceptions.TransientException: ForsetiClient[transactionId=280, clientId=4] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=283, clientId=5]} on NODE_RELATIONSHIP_GROUP_DELETE(606840), because holders of that lock are waiting for ForsetiClient[transactionId=280, clientId=4].\n",
      " Wait list:ExclusiveLock[\n",
      "Client[283] waits for [ForsetiClient[transactionId=280, clientId=4]]]\n",
      "\tat org.neo4j.driver.internal.util.Futures.blockingGet(Futures.java:144)\n",
      "\tat org.neo4j.driver.internal.InternalTransaction.run(InternalTransaction.java:60)\n",
      "\tat org.neo4j.driver.internal.AbstractQueryRunner.run(AbstractQueryRunner.java:37)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:64)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.write(BaseDataWriter.scala:45)\n",
      "\tat org.neo4j.spark.writer.Neo4jDataWriter.write(Neo4jDataWriter.scala:9)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:416)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tSuppressed: org.neo4j.driver.internal.util.ErrorUtil$InternalExceptionCause\n",
      "\t\tat org.neo4j.driver.internal.util.ErrorUtil.newNeo4jError(ErrorUtil.java:103)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageDispatcher.handleFailureMessage(InboundMessageDispatcher.java:122)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.unpackFailureMessage(CommonMessageReader.java:83)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.read(CommonMessageReader.java:59)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:83)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:35)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.MessageDecoder.channelRead(MessageDecoder.java:47)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t\t... 1 more\n",
      "\n",
      "22/06/21 12:27:27 ERROR TaskSetManager: Task 3 in stage 1.0 failed 1 times; aborting job\n",
      "22/06/21 12:27:27 ERROR OverwriteByExpressionExec: Data source write support org.neo4j.spark.writer.Neo4jBatchWriter@e9bf8ab is aborting.\n",
      "22/06/21 12:27:27 ERROR OverwriteByExpressionExec: Data source write support org.neo4j.spark.writer.Neo4jBatchWriter@e9bf8ab aborted.\n",
      "22/06/21 12:27:30 ERROR Neo4jDataWriter: Cannot commit the transaction because the following exception\n",
      "org.neo4j.driver.exceptions.TransientException: ForsetiClient[transactionId=286, clientId=8] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=283, clientId=5]} on NODE_RELATIONSHIP_GROUP_DELETE(190368), because holders of that lock are waiting for ForsetiClient[transactionId=286, clientId=8].\n",
      " Wait list:ExclusiveLock[\n",
      "Client[283] waits for [ForsetiClient[transactionId=286, clientId=8]]]\n",
      "\tat org.neo4j.driver.internal.util.Futures.blockingGet(Futures.java:144)\n",
      "\tat org.neo4j.driver.internal.InternalTransaction.run(InternalTransaction.java:60)\n",
      "\tat org.neo4j.driver.internal.AbstractQueryRunner.run(AbstractQueryRunner.java:37)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:64)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.write(BaseDataWriter.scala:45)\n",
      "\tat org.neo4j.spark.writer.Neo4jDataWriter.write(Neo4jDataWriter.scala:9)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:416)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tSuppressed: org.neo4j.driver.internal.util.ErrorUtil$InternalExceptionCause\n",
      "\t\tat org.neo4j.driver.internal.util.ErrorUtil.newNeo4jError(ErrorUtil.java:103)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageDispatcher.handleFailureMessage(InboundMessageDispatcher.java:122)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.unpackFailureMessage(CommonMessageReader.java:83)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.read(CommonMessageReader.java:59)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:83)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:35)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.MessageDecoder.channelRead(MessageDecoder.java:47)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t\t... 1 more\n",
      "22/06/21 12:27:30 ERROR Utils: Aborting task\n",
      "org.neo4j.driver.exceptions.TransientException: ForsetiClient[transactionId=286, clientId=8] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=283, clientId=5]} on NODE_RELATIONSHIP_GROUP_DELETE(190368), because holders of that lock are waiting for ForsetiClient[transactionId=286, clientId=8].\n",
      " Wait list:ExclusiveLock[\n",
      "Client[283] waits for [ForsetiClient[transactionId=286, clientId=8]]]\n",
      "\tat org.neo4j.driver.internal.util.Futures.blockingGet(Futures.java:144)\n",
      "\tat org.neo4j.driver.internal.InternalTransaction.run(InternalTransaction.java:60)\n",
      "\tat org.neo4j.driver.internal.AbstractQueryRunner.run(AbstractQueryRunner.java:37)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:64)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.writeBatch(BaseDataWriter.scala:93)\n",
      "\tat org.neo4j.spark.writer.BaseDataWriter.write(BaseDataWriter.scala:45)\n",
      "\tat org.neo4j.spark.writer.Neo4jDataWriter.write(Neo4jDataWriter.scala:9)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:416)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tSuppressed: org.neo4j.driver.internal.util.ErrorUtil$InternalExceptionCause\n",
      "\t\tat org.neo4j.driver.internal.util.ErrorUtil.newNeo4jError(ErrorUtil.java:103)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageDispatcher.handleFailureMessage(InboundMessageDispatcher.java:122)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.unpackFailureMessage(CommonMessageReader.java:83)\n",
      "\t\tat org.neo4j.driver.internal.messaging.common.CommonMessageReader.read(CommonMessageReader.java:59)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:83)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.InboundMessageHandler.channelRead0(InboundMessageHandler.java:35)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)\n",
      "\t\tat org.neo4j.driver.internal.async.inbound.MessageDecoder.channelRead(MessageDecoder.java:47)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\t\tat org.neo4j.driver.internal.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t\t... 1 more\n",
      "22/06/21 12:27:30 ERROR DataWritingSparkTask: Aborting commit for partition 2 (task 3, attempt 0, stage 1.0)\n",
      "22/06/21 12:27:30 ERROR DataWritingSparkTask: Aborted commit for partition 2 (task 3, attempt 0, stage 1.0)\n",
      "22/06/21 12:27:30 WARN TaskSetManager: Lost task 2.0 in stage 1.0 (TID 3) (192.168.0.178 executor driver): TaskKilled (Stage cancelled)\n",
      "22/06/21 12:28:03 ERROR Utils: Aborting taskge 2:>                  (0 + 1) / 1]\n",
      "org.apache.spark.TaskKilledException\n",
      "\tat org.apache.spark.TaskContextImpl.killTaskIfInterrupted(TaskContextImpl.scala:156)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:36)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:511)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificColumnarIterator.hasNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/06/21 12:28:03 ERROR DataWritingSparkTask: Aborting commit for partition 1 (task 2, attempt 0, stage 1.0)\n",
      "22/06/21 12:28:03 ERROR DataWritingSparkTask: Aborted commit for partition 1 (task 2, attempt 0, stage 1.0)\n",
      "22/06/21 12:28:03 WARN TaskSetManager: Lost task 1.0 in stage 1.0 (TID 2) (192.168.0.178 executor driver): TaskKilled (Stage cancelled)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=0, keywords=[Row(0='0.29808715592209734', 1='evasion attacks'), Row(0='0.3319272893390838', 1='machine learning'), Row(0='0.41272376995293325', 1='test time'), Row(0='0.3319272893390838', 1='machine learning'), Row(0='0.9848120123014036', 1='learning depends'), Row(0='1.0331193081207946', 1='attack scenario'), Row(0='0.41272376995293325', 1='test time'), Row(0='1.0331193081207946', 1='manipulating attack'), Row(0='0.4086077265811094', 1='attack samples'), Row(0='0.29808715592209734', 1='evasion attacks'), Row(0='1.1075239343161545', 1='simulate attack'), Row(0='1.1075239343161545', 1='attack scenarios'), Row(0='1.1075239343161545', 1='manipulate attack'), Row(0='0.4086077265811094', 1='attack samples'), Row(0='0.29808715592209734', 1='evasion attacks')])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_keywords.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query1 =\"\"\"UNWIND event.keywords as keyword\n",
    "MERGE (k:Keyword{word:keyword.`1`})\"\"\"\n",
    "\n",
    "query2 =\"\"\"match (a:Article{id:event.id})\n",
    "UNWIND event.keywords as keyword\n",
    "match (k:Keyword{word:keyword.`1`})\n",
    "with a,k,toInteger(keyword.`0`) as score\n",
    "MERGE (a)-[rel:ABOUT]->(k)\n",
    "ON CREATE SET rel.score = score\n",
    "ON MATCH SET rel.score = CASE WHEN rel.score > score THEN rel.score ELSE score END\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "with_keywords.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    ".option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    ".option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    ".option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    ".option(\"transaction.retries\", 5)\\\n",
    ".option(\"transaction.retry.timeout\", 5)\\\n",
    ".mode(\"Overwrite\")\\\n",
    ".option(\"query\", query1)\\\n",
    ".save()\n",
    "\n",
    "with_keywords.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    ".option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    ".option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    ".option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    ".option(\"transaction.retries\", 5)\\\n",
    ".option(\"transaction.retry.timeout\", 5)\\\n",
    ".mode(\"Append\")\\\n",
    ".option(\"query\", query2)\\\n",
    ".save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[id: bigint, keywords: array<struct<0:string,1:string>>]>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>   (0 + 3) / 4][Stage 55:>   (0 + 3) / 4][Stage 56:>   (0 + 1) / 4]\r"
     ]
    }
   ],
   "source": [
    "with_keywords.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"match (a:Article{id:event.id})\n",
    "    # set a.language=event.lang\"\"\"\n",
    "\n",
    "    # articles_abstracts_with_lang.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    # .option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    "    # .option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    "    # .option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    "    # .mode(\"append\")\\\n",
    "    # .option(\"query\", query)\\\n",
    "    # .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_en download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "[OK!]\n",
      "doc2vec_gigaword_wiki_300 download started this may take some time.\n",
      "Approximate size to download 312.3 MB\n",
      "[ | ]doc2vec_gigaword_wiki_300 download started this may take some time.\n",
      "Approximate size to download 312.3 MB\n",
      "[  ]Download done! Loading the resource.\n",
      "[ \\ ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import Doc2VecModel\n",
    "document = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "token = Tokenizer()\\\n",
    "  .setInputCols(\"document\")\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "norm = Normalizer()\\\n",
    "  .setInputCols([\"token\"])\\\n",
    "  .setOutputCol(\"normalized\")\\\n",
    "  .setLowercase(True)\n",
    "\n",
    "stops = StopWordsCleaner.pretrained()\\\n",
    "  .setInputCols(\"normalized\")\\\n",
    "  .setOutputCol(\"cleanedToken\")\n",
    "  \n",
    "doc2Vec = Doc2VecModel.pretrained(\"doc2vec_gigaword_wiki_300\", \"en\")\\\n",
    "  .setInputCols(\"cleanedToken\")\\\n",
    "  .setOutputCol(\"sentence_embeddings\")\n",
    "  \n",
    "pipeline_doc2vec = Pipeline(stages=[\n",
    "  document,\n",
    "  token,\n",
    "  norm,\n",
    "  stops,\n",
    "  doc2Vec\n",
    "])\n",
    "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
    "doc2vec_model = pipeline_doc2vec.fit(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, embeddings: array<float>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_doc2vec = doc2vec_model.transform(articles_abstracts).select(\"id\",F.col(\"sentence_embeddings.embeddings\")[0].alias(\"embeddings\"))\n",
    "with_doc2vec.cache()\n",
    "# only 1m 18.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(id=0, embeddings=[0.02049514278769493, 0.0027027390897274017, -0.02206415683031082, -0.014081479050219059, 0.02675016038119793, -0.0025557605549693108, -0.03921186923980713, -0.022662989795207977, 0.01931287720799446, -0.028936661779880524, 0.015005095861852169, -0.017352813854813576, 0.014226953499019146, -0.0012490303488448262, -0.0038129265885800123, 0.003299228847026825, -0.012594044208526611, 0.00601203041151166, 0.017957666888833046, 0.024490540847182274, -0.04826386272907257, 0.025399409234523773, -0.0011097918031737208, 0.042576540261507034, -0.023143433034420013, 0.004230480175465345, -0.02783290483057499, -0.05379168316721916, -0.003942739684134722, 0.0272237379103899, -0.022858165204524994, 0.011684686876833439, 0.0025437287986278534, -0.004211811814457178, -0.030333364382386208, 0.0006534804706461728, 0.0027076248079538345, -0.010169739834964275, 0.014752971939742565, 0.03539455309510231, 0.019348373636603355, -0.009497113525867462, 0.02914026379585266, -0.007100218441337347, -0.01578289084136486, -0.009364448487758636, -0.04503871500492096, 0.0008842918905429542, 0.01874093897640705, 0.01629556156694889, 0.026252513751387596, -0.022356083616614342, 0.012654365040361881, -0.0005208954680711031, 0.024472370743751526, -0.026965999975800514, 0.021037543192505836, 0.00932934321463108, -0.004678833298385143, 0.024570370092988014, -0.029008006677031517, 0.01182034332305193, -0.0017678857548162341, 0.004607729613780975, 0.027747467160224915, -0.015515103936195374, 0.0027785415295511484, -0.02423558570444584, 0.015382488258183002, 0.016816603019833565, 0.007466749753803015, -0.011099549941718578, -0.008243563584983349, 0.027636324986815453, 0.004550155717879534, -0.020404573529958725, -0.007612030487507582, -0.026162177324295044, 0.031154321506619453, 0.002911374205723405, -0.04779216647148132, -0.03251803293824196, 0.00822405330836773, 0.03231578692793846, 0.024691490456461906, -0.02048669569194317, -0.0014999479753896594, 0.036367811262607574, 0.0013888855464756489, -0.018843328580260277, 0.010037326253950596, 0.02869812399148941, 0.007880822755396366, 0.010892480611801147, -0.015600013546645641, 0.0002768542617559433, -0.007857643999159336, -0.0019940624479204416, 0.012373826466500759, 0.030845345929265022, -0.02151591330766678, 0.018306083977222443, -0.023572372272610664, 0.008224156685173512, -0.002520687645301223, 0.012271448038518429, 0.02235572040081024, 0.005620874930173159, 0.015774736180901527, 0.030890807509422302, 0.002291948301717639, -0.015397855080664158, -0.019699500873684883, 0.008863002061843872, 0.006817031651735306, 0.0075248535722494125, 0.024382302537560463, 0.029389286413788795, -0.0023522505071014166, 0.009930239990353584, -0.025244848802685738, 0.04416778311133385, 0.014900053851306438, -0.01812889613211155, -0.005423916969448328, 0.016256200149655342, 0.01949833519756794, -0.005984552204608917, 0.011398647911846638, -0.0032735520508140326, -0.014180508442223072, -0.011287384666502476, -0.03600466623902321, -0.0013506260002031922, -0.030462944880127907, 0.013830258511006832, 0.0018052704399451613, 0.008873114362359047, 0.02939959429204464, -0.009793815203011036, 0.006747665349394083, -1.1614407412707806e-05, 0.0017366460524499416, 0.024829380214214325, -0.013312104158103466, -0.028088897466659546, -0.004532770253717899, -0.029765121638774872, 0.01410600170493126, -0.006939989980310202, 0.0017604894237592816, 0.004546865355223417, 0.015442762523889542, 0.025594418868422508, 0.004054530989378691, 0.008373800665140152, 0.0005267183878459036, -0.012460644356906414, 0.01438265573233366, 0.02346092462539673, 0.029504964128136635, -0.03132003918290138, 0.023022793233394623, 0.012386512011289597, -0.008746468462049961, -0.01141170784831047, 0.03697606921195984, 0.005169886630028486, -0.047957923263311386, -0.0016039562178775668, 0.004989291075617075, -0.049743566662073135, 0.06305954605340958, -0.012950862757861614, -0.05950364097952843, -0.007487186696380377, 0.016485316678881645, -0.01631753146648407, -0.030325792729854584, 0.025380706414580345, 0.0008468852029182017, -0.03474815562367439, 0.024509072303771973, -0.03091847151517868, -0.03582896292209625, -0.048943039029836655, 0.020405160263180733, -0.031029030680656433, -0.03627001866698265, 0.03759562596678734, 0.01027432270348072, 0.022935738787055016, -0.008238782174885273, -0.02651892602443695, 0.01975693367421627, 0.0028453341219574213, 0.00456188665702939, -0.04640893265604973, 0.007575917989015579, 0.0021615319419652224, 0.0011538444086909294, 0.004585572052747011, -0.007299581542611122, -0.03339086100459099, -0.024151815101504326, 0.005810365080833435, 0.023522282019257545, 0.05306458845734596, -0.0582144558429718, -0.007529666181653738, 0.059019703418016434, 0.001622312585823238, -0.002376031829044223, 0.04431624710559845, -0.04672780632972717, -0.02756817638874054, -0.033750999718904495, 0.034872885793447495, -0.015267386101186275, -0.03358391672372818, -0.024710871279239655, -0.02247295342385769, 0.030869893729686737, -0.020582694560289383, -0.021996518597006798, -0.03432542830705643, 0.008851188234984875, -0.025540687143802643, -0.014117388986051083, 0.007757427170872688, 0.003945415839552879, 0.011337927542626858, 0.023989317938685417, -0.034629661589860916, -0.021922849118709564, 0.0027928121853619814, 0.030251460149884224, 0.03651801124215126, -0.012741616927087307, 0.023721493780612946, 0.032332710921764374, 0.010588145814836025, -0.014355126768350601, -0.02575499750673771, -0.03808116167783737, 0.0006723224651068449, 0.006186489015817642, 0.00359431398101151, 0.019355906173586845, -0.03324732929468155, -0.016296176239848137, -0.0032173029612749815, -0.0005261757178232074, 0.025937991216778755, -0.01792011596262455, 0.055038388818502426, -0.040074534714221954, 0.027739206328988075, -0.0198050644248724, -0.013044060207903385, 0.020709708333015442, 0.0011671456741169095, 0.004734761547297239, 0.02507845126092434, -0.009028698317706585, -0.03221882879734039, 0.005697824060916901, -0.0028153324965387583, -0.010812885127961636, 0.02595091052353382, -0.04382146894931793, -0.03239988163113594, -0.01107017695903778, -0.017987752333283424, 0.0053635407239198685, 0.0010370415402576327, 0.007341750431805849, 0.018632175400853157, -0.01928747072815895, -0.034815713763237, -0.008547386154532433, -0.03765640780329704, -0.0015280419029295444, 0.00031837381538935006, 0.031053779646754265, -0.026577195152640343, -0.01364303007721901, -0.013965957798063755, -0.03261541947722435, -0.02948630414903164, -0.03775601089000702, 0.009297649376094341, -0.037410106509923935, 0.035359401255846024, 0.006463113706558943, 0.017344508320093155, 0.024191996082663536, 0.00946693867444992, 0.0348287969827652, 0.03033405728638172])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_doc2vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"match (a:Article{id:event.id})\n",
    "set a.embeddings=event.embeddings\"\"\"\n",
    "\n",
    "with_doc2vec.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    ".option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    ".option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    ".option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    ".mode(\"append\")\\\n",
    ".option(\"query\", query)\\\n",
    ".save()\n",
    "# 1m 59s upload to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, result: array<string>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_stems = stemmer_model.transform(articles_abstracts).select(\"id\",\"cleanedStem.result\")#,F.col(\"normalized.result\"))\n",
    "with_stems.cache()\n",
    "# 1m 9.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(sum(size)=16144851)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 3) / 4]\r"
     ]
    }
   ],
   "source": [
    "with_stems.select(F.size(F.col(\"result\")).alias(\"size\")).agg(F.sum(\"size\")).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>   (0 + 3) / 4][Stage 55:>   (0 + 3) / 4][Stage 56:>   (0 + 1) / 4]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000066?line=0'>1</a>\u001b[0m with_stems\u001b[39m.\u001b[39;49mhead(\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1589\u001b[0m, in \u001b[0;36mDataFrame.head\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     rs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead(\u001b[39m1\u001b[39m)\n\u001b[1;32m   1588\u001b[0m     \u001b[39mreturn\u001b[39;00m rs[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m rs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1589\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(n)\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:728\u001b[0m, in \u001b[0;36mDataFrame.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtake\u001b[39m(\u001b[39mself\u001b[39m, num):\n\u001b[1;32m    719\u001b[0m     \u001b[39m\"\"\"Returns the first ``num`` rows as a :class:`list` of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \n\u001b[1;32m    721\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[39m    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlimit(num)\u001b[39m.\u001b[39;49mcollect()\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:677\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[1;32m    669\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[39m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sc) \u001b[39mas\u001b[39;00m css:\n\u001b[0;32m--> 677\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcollectToPython()\n\u001b[1;32m    678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(PickleSerializer())))\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1304\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1034\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError while sending\u001b[39m\u001b[39m\"\u001b[39m, e, proto\u001b[39m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[39mif\u001b[39;00m answer\u001b[39m.\u001b[39mstartswith(proto\u001b[39m.\u001b[39mRETURN_MESSAGE):\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/21 11:18:03 ERROR OverwriteByExpressionExec: Data source write support org.neo4j.spark.writer.Neo4jBatchWriter@627342ad is aborting.\n",
      "22/06/21 11:18:03 ERROR OverwriteByExpressionExec: Data source write support org.neo4j.spark.writer.Neo4jBatchWriter@627342ad aborted.\n",
      "[Stage 50:>   (0 + 3) / 4][Stage 55:>   (0 + 3) / 4][Stage 56:>   (0 + 1) / 4]\r"
     ]
    }
   ],
   "source": [
    "with_stems.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>   (0 + 3) / 4][Stage 55:>   (0 + 3) / 4][Stage 56:>   (0 + 1) / 4]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=0'>1</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mmatch (a:Article\u001b[39m\u001b[39m{\u001b[39m\u001b[39mid:event.id})\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=1'>2</a>\u001b[0m \u001b[39mwith a,event\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=2'>3</a>\u001b[0m \u001b[39mUNWIND event.result as stem\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=6'>7</a>\u001b[0m \u001b[39mON CREATE SET rel.weight = 1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=7'>8</a>\u001b[0m \u001b[39mON MATCH SET rel.weight = rel.weight+1\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=9'>10</a>\u001b[0m with_stems\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mformat(\u001b[39m\"\u001b[39;49m\u001b[39morg.neo4j.spark.DataSource\u001b[39;49m\u001b[39m\"\u001b[39;49m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=10'>11</a>\u001b[0m \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbolt://192.168.0.178:7687\u001b[39;49m\u001b[39m\"\u001b[39;49m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=11'>12</a>\u001b[0m \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mauthentication.basic.username\u001b[39;49m\u001b[39m\"\u001b[39;49m, os\u001b[39m.\u001b[39;49menviron[\u001b[39m\"\u001b[39;49m\u001b[39mNEO4J_LOGIN\u001b[39;49m\u001b[39m\"\u001b[39;49m])\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=12'>13</a>\u001b[0m \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mauthentication.basic.password\u001b[39;49m\u001b[39m\"\u001b[39;49m, os\u001b[39m.\u001b[39;49menviron[\u001b[39m\"\u001b[39;49m\u001b[39mNEO4J_PASSWORD\u001b[39;49m\u001b[39m\"\u001b[39;49m])\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=13'>14</a>\u001b[0m \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mtransaction.retries\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m5\u001b[39;49m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=14'>15</a>\u001b[0m \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mtransaction.retry.timeout\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m5\u001b[39;49m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=15'>16</a>\u001b[0m \u001b[39m.\u001b[39;49mmode(\u001b[39m\"\u001b[39;49m\u001b[39mOverwrite\u001b[39;49m\u001b[39m\"\u001b[39;49m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=16'>17</a>\u001b[0m \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m, query)\\\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vergenter/Sources/masterthesis/data_exploration/notebook.ipynb#ch0000061?line=17'>18</a>\u001b[0m \u001b[39m.\u001b[39;49msave()\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1107\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mformat\u001b[39m)\n\u001b[1;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jwrite\u001b[39m.\u001b[39msave(path)\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1304\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1034\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/Venvs/sparkNLPVenv/lib/python3.10/site-packages/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError while sending\u001b[39m\u001b[39m\"\u001b[39m, e, proto\u001b[39m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[39mif\u001b[39;00m answer\u001b[39m.\u001b[39mstartswith(proto\u001b[39m.\u001b[39mRETURN_MESSAGE):\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>   (0 + 3) / 4][Stage 55:>   (0 + 3) / 4][Stage 56:>   (0 + 1) / 4]\r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"match (a:Article{id:event.id})\n",
    "with a,event\n",
    "UNWIND event.result as stem\n",
    "MERGE (s:Stem{word:stem})\n",
    "with a,s\n",
    "MERGE (a)-[rel:CONTAINS]->(s)\n",
    "ON CREATE SET rel.weight = 1\n",
    "ON MATCH SET rel.weight = rel.weight+1\"\"\"\n",
    "\n",
    "with_stems.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    ".option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    ".option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    ".option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    ".option(\"transaction.retries\", 5)\\\n",
    ".option(\"transaction.retry.timeout\", 5)\\\n",
    ".mode(\"Overwrite\")\\\n",
    ".option(\"query\", query)\\\n",
    ".save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_en download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import PerceptronModel,SentenceDetector,Tokenizer,Stemmer,Normalizer,StopWordsCleaner\n",
    "from sparknlp.base import DocumentAssembler,Pipeline,LightPipeline\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "  .setInputCol(\"text\") \\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetector() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "  .setInputCols([\"token\"]) \\\n",
    "  .setOutputCol(\"stem\")\n",
    "\n",
    "norm = Normalizer()\\\n",
    "  .setInputCols([\"token\"])\\\n",
    "  .setOutputCol(\"normalized\")\\\n",
    "  .setLowercase(True)\n",
    "\n",
    "stops = StopWordsCleaner.pretrained()\\\n",
    "  .setInputCols(\"normalized\")\\\n",
    "  .setOutputCol(\"cleanedStem\")\n",
    "\n",
    "\n",
    "stem_pipeline = Pipeline(stages=[\n",
    "  document_assembler,\n",
    "  sentence,\n",
    "  tokenizer,\n",
    "  stemmer,\n",
    "  norm,\n",
    "  stops,\n",
    "])\n",
    "\n",
    "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
    "stem_model = stem_pipeline.fit(empty_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, result: array<string>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_stems = stem_model.transform(articles_abstracts).select(\"id\",\"cleanedStem.result\")#,F.col(\"normalized.result\"))\n",
    "with_stems.persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=0, result=['evasion', 'attacks', 'machine', 'learning', 'test', 'time', 'securitysensitive', 'applications', 'success', 'machine', 'learning', 'depends', 'vetting', 'resistance', 'adversarial', 'data', 'pertinent', 'wellmotivated', 'attack', 'scenario', 'adversary', 'attempt', 'evade', 'deployed', 'system', 'test', 'time', 'carefully', 'manipulating', 'attack', 'samples', 'work', 'present', 'simple', 'effective', 'gradientbased', 'approach', 'exploited', 'systematically', 'assess', 'security', 'widelyused', 'classification', 'algorithms', 'evasion', 'attacks', 'recently', 'proposed', 'framework', 'security', 'evaluation', 'simulate', 'attack', 'scenarios', 'exhibit', 'risk', 'levels', 'classifier', 'increasing', 'attackers', 'knowledge', 'system', 'ability', 'manipulate', 'attack', 'samples', 'classifier', 'designer', 'picture', 'classifier', 'performance', 'evasion', 'attacks', 'perform', 'informed', 'model', 'selection', 'parameter', 'setting', 'evaluate', 'approach', 'relevant', 'security', 'task', 'malware', 'detection', 'pdf', 'files', 'show', 'systems', 'easily', 'evaded', 'sketch', 'countermeasures', 'suggested', 'analysis'])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_stems.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import ArrayType,StructType,StructField,StringType\n",
    "\n",
    "def get_sliding_window(window_size:int):\n",
    "    def window(arr:list):\n",
    "        arrlen = len(arr)\n",
    "        size = min(arrlen*(arrlen-1)//2,window_size*(window_size-1)//2) + max(0,(arrlen-window_size))*(window_size-1)\n",
    "        result = [None] * size\n",
    "        index = 0\n",
    "        for i in range(size):\n",
    "            for j in range(i+1,min(i+window_size,arrlen)):\n",
    "                result[index] = (arr[i],arr[j]) if (arr[i]>arr[j]) else (arr[j],arr[i])\n",
    "                index+=1\n",
    "        return result\n",
    "    return F.udf(window,ArrayType(StructType([StructField(\"first\",StringType(),False),StructField(\"second\",StringType(),False)])))\n",
    "\n",
    "mySlidingPairs2 = get_sliding_window(7)\n",
    "coocurence = with_stems.select(F.explode(mySlidingPairs2(\"result\")).alias(\"result\")).select(\"result.first\",\"result.second\").groupBy(\"first\",\"second\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[first: string, second: string, count: bigint]>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coocurence.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "coocurence.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    ".option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    ".option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    ".option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    ".option(\"relationship\", \"COOCURES\")\\\n",
    ".option(\"relationship.save.strategy\", \"keys\")\\\n",
    ".option(\"relationship.properties\", \"count:weight\")\\\n",
    ".option(\"relationship.source.labels\", \":Stem\")\\\n",
    ".option(\"relationship.source.save.mode\", \"Match\")\\\n",
    ".option(\"relationship.source.node.keys\", \"first:word\")\\\n",
    ".option(\"relationship.target.labels\", \":Stem\")\\\n",
    ".option(\"relationship.target.node.keys\", \"second:word\")\\\n",
    ".option(\"relationship.target.save.mode\", \"Match\")\\\n",
    ".option(\"transaction.retries\", 5)\\\n",
    ".option(\"transaction.retry.timeout\", 5)\\\n",
    ".mode(\"Append\")\\\n",
    ".save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_stems = with_stems.select(F.explode(\"result\").alias(\"result\")).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"MERGE (:Stem{word:event.result})\n",
    "\"\"\"\n",
    "\n",
    "distinct_stems.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    ".option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    ".option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    ".option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    ".option(\"transaction.retries\", 5)\\\n",
    ".option(\"transaction.retry.timeout\", 5)\\\n",
    ".mode(\"Overwrite\")\\\n",
    ".option(\"query\", query1)\\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_stem_relation = with_stems.select(\"id\",F.explode(\"result\").alias(\"result\")).groupBy(\"id\",\"result\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=10, result='markovian', count=1)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_stem_relation.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# query2 = \"\"\"match (a:Article{id:event.id}),(s:Stem{word:event.result})\n",
    "# with a,s,event\n",
    "# MERGE (a)-[rel:CONTAINS{weight:event.count}]->(s)\"\"\"\n",
    "\n",
    "article_stem_relation.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    ".option(\"url\", \"bolt://192.168.0.178:7687\")\\\n",
    ".option(\"authentication.basic.username\", os.environ[\"NEO4J_LOGIN\"])\\\n",
    ".option(\"authentication.basic.password\", os.environ[\"NEO4J_PASSWORD\"])\\\n",
    ".option(\"relationship\", \"CONTAINS\")\\\n",
    ".option(\"relationship.save.strategy\", \"keys\")\\\n",
    ".option(\"relationship.properties\", \"count:weight\")\\\n",
    ".option(\"relationship.source.labels\", \":Article\")\\\n",
    ".option(\"relationship.source.save.mode\", \"Match\")\\\n",
    ".option(\"relationship.source.node.keys\", \"id:id\")\\\n",
    ".option(\"relationship.target.labels\", \":Stem\")\\\n",
    ".option(\"relationship.target.node.keys\", \"result:word\")\\\n",
    ".option(\"relationship.target.save.mode\", \"Match\")\\\n",
    ".option(\"transaction.retries\", 5)\\\n",
    ".option(\"transaction.retry.timeout\", 5)\\\n",
    ".mode(\"Append\")\\\n",
    ".save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('igraphvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ab0d5cd42251145a22f3de6141280eb8e2869ae55fe1bb572523b41626fd4b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
